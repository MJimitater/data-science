{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import git2net\n",
    "\n",
    "#path to copy of virgin db:\n",
    "sqlite_db_file = '/home/luc/pip/git2net/group_work_1/git2net_tutorial (Kopie).db'\n",
    "\n",
    "#set variable to whatever folder the to-be-mined git repository is located:\n",
    "repo_dir = '/home/luc/pip/git2net/ds_gw_1/TLP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment this block, if mining is wished\n",
    "\n",
    "#check, if database file is there; remove if yes\n",
    "#if os.path.exists(sqlite_db_file):\n",
    "#    os.remove(sqlite_db_file)\n",
    "#    print('sqlite_db_file removed!')\n",
    "\n",
    "#mining process: \n",
    "#repo_dir: to-be-mined git repository\n",
    "#sqlite_db_file: to-be-stored values in database\n",
    "\n",
    "#git2net.mine_git_repo(repo_dir, sqlite_db_file)\n",
    "\n",
    "#git2net.mining_state_summary(repo_dir, sqlite_db_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "#connect to database file:\n",
    "con = sqlite3.connect(sqlite_db_file)\n",
    "c = con.cursor()\n",
    "\n",
    "\n",
    "#create a new table with the desired column names:\n",
    "query0=\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS df2(\n",
    "    hash TEXT PRIMARY KEY,\n",
    "    committer_name TEXT,\n",
    "    committer_date TEXT,\n",
    "    original_commit_deletion TEXT,\n",
    "    levenshtein_dist INTEGER);\n",
    "\"\"\"\n",
    "\n",
    "#select only rows of table \"edits\", where edit_type='replacement', \n",
    "#merge this with table \"commits\" along the key 'hash',\n",
    "#group this by unique hashes, taking the sum of the levenshtein dist of same hashes\n",
    "#finally, insert this into a new table \"df2\" to avoid key words as column names:\n",
    "query1=\"\"\"\n",
    "    INSERT INTO df2(hash, committer_name, committer_date, original_commit_deletion, levenshtein_dist)\n",
    "    SELECT hash, committer_name, committer_date, original_commit_deletion, \"SUM(levenshtein_dist)\"\n",
    "    FROM\n",
    "    (\n",
    "    SELECT \n",
    "    hash,\n",
    "    committer_name,\n",
    "    committer_date,\n",
    "    original_commit_deletion,\n",
    "    SUM(levenshtein_dist)\n",
    "    FROM(SELECT * FROM edits INNER JOIN commits ON commits.hash = edits.commit_hash WHERE edit_type = 'replacement')\n",
    "    GROUP BY hash\n",
    "    );\n",
    "\"\"\"\n",
    "\n",
    "#count the distinct committer names:\n",
    "query1_1=\"\"\"\n",
    "    SELECT count(DISTINCT committer_name) FROM df2;\n",
    "\"\"\"\n",
    "\n",
    "#select the distinct committer names\n",
    "query1_2=\"\"\"\n",
    "    SELECT DISTINCT committer_name FROM df2;\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#execute the two queries on the database:\n",
    "c.execute(query0)\n",
    "c.execute(query1)\n",
    "c.execute(query1_1)\n",
    "\n",
    "#store amount of distinct committer names as int...\n",
    "number_committers = c.fetchone()[0]\n",
    "\n",
    "#...before executing the next query:\n",
    "c.execute(query1_2)\n",
    "\n",
    "#store names of committers in list:\n",
    "committer_list = c.fetchall()\n",
    "\n",
    "\n",
    "#save the queries:\n",
    "con.commit()\n",
    "\n",
    "#close the database to make it accessible for others:\n",
    "con.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[]\n"
    }
   ],
   "source": [
    "#create new empty table:\n",
    "query01=\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS df3(\n",
    "    hash TEXT PRIMARY KEY,\n",
    "    committer_name TEXT,\n",
    "    committer_date TEXT,\n",
    "    original_commit_deletion TEXT,\n",
    "    levenshtein_dist INTEGER);\n",
    "\"\"\"\n",
    "\n",
    "#sort committer_date ascending:\n",
    "query2=\"\"\"\n",
    "    INSERT INTO df3(hash, committer_name, committer_date, original_commit_deletion, levenshtein_dist)\n",
    "    SELECT *\n",
    "    FROM\n",
    "    (\n",
    "    SELECT * \n",
    "    FROM df2 \n",
    "    ORDER BY committer_date ASC\n",
    "    );\n",
    "\"\"\"\n",
    "\n",
    "#delete table df2:\n",
    "query3=\"\"\"\n",
    "    DROP TABLE df2;\n",
    "\"\"\"\n",
    "\n",
    "#delete table df3:\n",
    "#query4=\"\"\"\n",
    "#    DROP TABLE df3;\n",
    "#\"\"\"\n",
    "\n",
    "\n",
    "#ordering:\n",
    "#query0, query2_edited, query3\n",
    "#then:\n",
    "#query01, query2_edited, query4\n",
    "\n",
    "\n",
    "con = sqlite3.connect(sqlite_db_file)\n",
    "c = con.cursor()\n",
    "\n",
    "#execute the queries:\n",
    "c.execute(query01)\n",
    "c.execute(query2)\n",
    "c.execute(query3)\n",
    "#result: df3\n",
    "\n",
    "print(c.fetchmany(5))\n",
    "\n",
    "con.commit()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(sqlite_db_file)\n",
    "\n",
    "#output df2 as a pandas dataframe\n",
    "df = pd.read_sql_query(\"SELECT * FROM df3;\", con=con)\n",
    "\n",
    "#turn Pandas dataframe into numpy array:\n",
    "df = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#function for adding a full-length '0'-column to the dataframe:\n",
    "def add_column(df):\n",
    "    new_column = np.array(np.zeros(df.shape[0]))\n",
    "    return np.column_stack((df, new_column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add column:\n",
    "df = add_column(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "2010-01-22 18:16:44\n"
    }
   ],
   "source": [
    "#make date stamps readible, by turning them into a datetime-object:\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "def date_to_int(date_str):\n",
    "    return datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "print(date_to_int(df[0][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate amount of time (in seconds) since last commit for every authors commit; save values in the newly created column\n",
    "\n",
    "for i in range(df.shape[0]-1):\n",
    "    #grab the author and his commit_time:\n",
    "    author = df[i][1]\n",
    "    commit_time = df[i][2]\n",
    "    for j in range(i+1,df.shape[0]):\n",
    "        #search for the his next commit:\n",
    "        author_next = df[j][1]\n",
    "        commit_time_next = df[j][2]\n",
    "        #if there is a \"next commit\", calculate the commit_time differences (in total seconds) and save the value in the last column:\n",
    "        if author == author_next:\n",
    "                df[j][5] = (date_to_int(commit_time_next) - date_to_int(commit_time)).total_seconds()\n",
    "                break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(942, 7)\n"
    }
   ],
   "source": [
    "#add empty 6th column:\n",
    "df = add_column(df)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate a measure for productivity:\n",
    "#levenshtein_dist / time_between_commits = levenshtein_dist per second\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "        #if time_between_commits = 0, then set productivity to 0\n",
    "    if df[i][5] == 0:\n",
    "        df[i][6] = 0\n",
    "        #else, calculate productivity measure and store in 6th column\n",
    "    else:     \n",
    "        df[i][6] = df[i][4] / df[i][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add empty 7th column:\n",
    "df = add_column(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find out, if author collaborated or not:\n",
    "#'1' if his parents hash is another authors commit hash,\n",
    "#'0' if not\n",
    "#add this boolean in a separate column:\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    parent_hash = df[i][3]\n",
    "    #set orig_author to default 'nobody'\n",
    "    #(important for genesis commit hashes)\n",
    "    orig_author = 'nobody'\n",
    "    for j in range(i):\n",
    "        #check whether any other prior hash is from the same author\n",
    "        if df[j][0] == parent_hash:\n",
    "            #update orig_author with real author name:\n",
    "            orig_author = df[j][1]\n",
    "            #if original hash found, then break:\n",
    "            break\n",
    "    #set a place holder in the 7th column:\n",
    "    df[i][7] = 'no parent_hash'\n",
    "    #if author collaborated, save '1', if not, save '0':\n",
    "    #only iff orig_author was another author, did the author collaborate:\n",
    "    if orig_author != df[i][1] and orig_author != 'nobody':\n",
    "        df[i][7] = 1\n",
    "    else:\n",
    "        df[i][7] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete commit_hash:\n",
    "df = np.delete(df,0,1)\n",
    "#delete commit_time:\n",
    "df = np.delete(df,1,1)\n",
    "#delete parent_hash:\n",
    "df = np.delete(df,1,1)\n",
    "#delete levensthein_dist:\n",
    "df = np.delete(df,1,1)\n",
    "#delete time_between_commits:\n",
    "df = np.delete(df,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(942, 3)\n"
    }
   ],
   "source": [
    "#turn numpy array into pandas dataframe:\n",
    "#insert first column of df as 'committer_names':\n",
    "pdf = pd.DataFrame({'committer_names': df[:,0]})\n",
    "#insert second column of df as 'productivity_per_second':\n",
    "pdf['productivity_per_second'] = df[:,1]\n",
    "#insert third column of df as 'collab_bool':\n",
    "pdf['collab_bool'] = df[:,2]\n",
    "\n",
    "print(pdf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(942,)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf['productivity_per_second'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (942,922) and (942,922) not aligned: 922 (dim 1) != 942 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-cbd0213208bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/pip/git2net/pip_ds/lib/python3.7/site-packages/statsmodels/regression/linear_model.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, yname, xname, title, alpha)\u001b[0m\n\u001b[1;32m   2483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m         \u001b[0mrsquared_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_constant\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m' (uncentered)'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2485\u001b[0;31m         top_right = [('R-squared' + rsquared_type + ':', [\"%#8.3f\" % self.rsquared]),\n\u001b[0m\u001b[1;32m   2486\u001b[0m                      \u001b[0;34m(\u001b[0m\u001b[0;34m'Adj. R-squared'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrsquared_type\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m':'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"%#8.3f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsquared_adj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2487\u001b[0m                      \u001b[0;34m(\u001b[0m\u001b[0;34m'F-statistic:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"%#8.4g\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pip/git2net/pip_ds/lib/python3.7/site-packages/statsmodels/tools/decorators.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, type)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0m_cachedval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cachedval\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0m_cachedval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m             \u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_cachedval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pip/git2net/pip_ds/lib/python3.7/site-packages/statsmodels/regression/linear_model.py\u001b[0m in \u001b[0;36mrsquared\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1634\u001b[0m         \"\"\"\n\u001b[1;32m   1635\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_constant\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1636\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mssr\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcentered_tss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1637\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mssr\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muncentered_tss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pip/git2net/pip_ds/lib/python3.7/site-packages/statsmodels/tools/decorators.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, type)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0m_cachedval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cachedval\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0m_cachedval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m             \u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_cachedval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pip/git2net/pip_ds/lib/python3.7/site-packages/statsmodels/regression/linear_model.py\u001b[0m in \u001b[0;36mssr\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1582\u001b[0m         \u001b[0;34m\"\"\"Sum of squared (whitened) residuals.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1583\u001b[0m         \u001b[0mwresid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwresid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1584\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwresid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwresid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1586\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcache_readonly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (942,922) and (942,922) not aligned: 922 (dim 1) != 942 (dim 0)"
     ]
    }
   ],
   "source": [
    "pdf['productivity_per_second'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.ols(formula='productivity_per_second ~ collab_bool + committer_names', data = pdf)\n",
    "fit = model.fit()\n",
    "\n",
    "print(fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(942, 19)\n"
    }
   ],
   "source": [
    "model = sm.ols(formula='productivity_per_second ~ collab_bool + committer_names', data = pdf)\n",
    "fit = model.fit()\n",
    "\n",
    "print(fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete all the other columns that are not needed for the regression analysis:\n",
    "#from df, delete row/column number 0, with axis column ('1'): \n",
    "df = np.delete(df,0,1)\n",
    "df = np.delete(df,0,1)\n",
    "df = np.delete(df,0,1)\n",
    "df = np.delete(df,0,1)\n",
    "df = np.delete(df,0,1)\n",
    "df = np.delete(df,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(942, 13)\n"
    }
   ],
   "source": [
    "#turn numpy array into pandas dataframe:\n",
    "#insert first column of df as 'productivity_per_second':\n",
    "pdf = pd.DataFrame({'productivity_per_second': df[:,0]})\n",
    "#insert second column of df as 'collab_bool':\n",
    "pdf['collab_bool'] = df[:,1]\n",
    "\n",
    "\n",
    "for i in range(number_committers):\n",
    "    #insert the dummy variable columns, \n",
    "    #take the committer_name as column name\n",
    "    pdf[committer_list[i][0]] = df[:,i+2]\n",
    "\n",
    "print(pdf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['collab_bool',\n 'Thomas Koch',\n 'GitHub',\n 'SammysHP',\n 'André Erdmann',\n 'Aaditya Bagga',\n 'Timofey Titovets',\n 'Connor Prussin',\n 'TK',\n 'Kai-Heng Feng',\n 'Maxime Gauduin',\n 'Qiang Yu']"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#turn list of string-tuples into list of single-strings:\n",
    "X = [i[0] for i in committer_list]\n",
    "#insert the string 'collab_bool' at the first spot of X:\n",
    "X.insert(0,'collab_bool')\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[-3.79310801e+12]\n[[-1.07474422e+00  3.79310801e+12  3.79310801e+12  3.79310801e+12\n   3.79310801e+12  3.79310801e+12  3.79310801e+12  3.79310801e+12\n   3.79310801e+12  3.79310801e+12  3.79310801e+12  3.79310801e+12]]\n"
    }
   ],
   "source": [
    "#perform multiple linear regression:\n",
    "\n",
    "#load the sklearn modules:\n",
    "from sklearn.linear_model import LinearRegression\n",
    "mlr = LinearRegression()\n",
    "\n",
    "#fit the model:\n",
    "#Independent variables: all the columns with name of the different committers\n",
    "#Dependent variable: the productivity_per_second column \n",
    "mlr.fit(pdf[X], pdf[['productivity_per_second']])\n",
    "\n",
    "#Print intercept:\n",
    "print(mlr.intercept_)\n",
    "\n",
    "#Print all coefficients:\n",
    "print(mlr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.30371094]])"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#try a prediction:\n",
    "#what is the productivity_per_second for thomas_koch, who is not collaborating? :\n",
    "koch_not_collab = np.array([[0,1,0,0,0,0,0,0,0,0,0,0]])\n",
    "\n",
    "mlr.predict(koch_not_collab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Coefficients =  [[-3.76887392e-02 -3.67486755e+12 -3.67486755e+12 -3.67486755e+12\n  -3.67486755e+12 -3.67486755e+12 -3.67486755e+12 -3.67486755e+12\n  -3.67486755e+12 -3.67486755e+12 -3.67486755e+12 -3.67486755e+12]]\n"
    }
   ],
   "source": [
    "#Perform Robust Regression:\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "model = linear_model.RANSACRegressor(min_samples=10, residual_threshold=5, max_trials=100)\n",
    "model.fit(pdf[X], pdf[['productivity_per_second']])\n",
    "\n",
    "print(\"Coefficients = \", model.estimator_.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.04199219]])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(koch_not_collab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "PatsyError",
     "evalue": "categorical data cannot be >1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPatsyError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-f047396f0cac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformula\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformula\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'productivity_per_second ~ pdf[X]'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mfit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pip/git2net/pip_ds/lib/python3.7/site-packages/statsmodels/base/model.py\u001b[0m in \u001b[0;36mfrom_formula\u001b[0;34m(cls, formula, data, subset, drop_cols, *args, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         tmp = handle_formula_data(data, None, formula, depth=eval_env,\n\u001b[0;32m--> 159\u001b[0;31m                                   missing=missing)\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesign_info\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pip/git2net/pip_ds/lib/python3.7/site-packages/statsmodels/formula/formulatools.py\u001b[0m in \u001b[0;36mhandle_formula_data\u001b[0;34m(Y, X, formula, depth, missing)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_using_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             result = dmatrices(formula, Y, depth, return_type='dataframe',\n\u001b[0;32m---> 65\u001b[0;31m                                NA_action=na_action)\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             result = dmatrices(formula, Y, depth, return_type='dataframe',\n",
      "\u001b[0;32m~/pip/git2net/pip_ds/lib/python3.7/site-packages/patsy/highlevel.py\u001b[0m in \u001b[0;36mdmatrices\u001b[0;34m(formula_like, data, eval_env, NA_action, return_type)\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0meval_env\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEvalEnvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_env\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     (lhs, rhs) = _do_highlevel_design(formula_like, data, eval_env,\n\u001b[0;32m--> 310\u001b[0;31m                                       NA_action, return_type)\n\u001b[0m\u001b[1;32m    311\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mPatsyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model is missing required outcome variables\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pip/git2net/pip_ds/lib/python3.7/site-packages/patsy/highlevel.py\u001b[0m in \u001b[0;36m_do_highlevel_design\u001b[0;34m(formula_like, data, eval_env, NA_action, return_type)\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     design_infos = _try_incr_builders(formula_like, data_iter_maker, eval_env,\n\u001b[0;32m--> 165\u001b[0;31m                                       NA_action)\n\u001b[0m\u001b[1;32m    166\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdesign_infos\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         return build_design_matrices(design_infos, data,\n",
      "\u001b[0;32m~/pip/git2net/pip_ds/lib/python3.7/site-packages/patsy/highlevel.py\u001b[0m in \u001b[0;36m_try_incr_builders\u001b[0;34m(formula_like, data_iter_maker, eval_env, NA_action)\u001b[0m\n\u001b[1;32m     68\u001b[0m                                       \u001b[0mdata_iter_maker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                                       \u001b[0meval_env\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                                       NA_action)\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pip/git2net/pip_ds/lib/python3.7/site-packages/patsy/build.py\u001b[0m in \u001b[0;36mdesign_matrix_builders\u001b[0;34m(termlists, data_iter_maker, eval_env, NA_action)\u001b[0m\n\u001b[1;32m    694\u001b[0m                                                    \u001b[0mfactor_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m                                                    \u001b[0mdata_iter_maker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m                                                    NA_action)\n\u001b[0m\u001b[1;32m    697\u001b[0m     \u001b[0;31m# Now we need the factor infos, which encapsulate the knowledge of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0;31m# how to turn any given factor into a chunk of data:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pip/git2net/pip_ds/lib/python3.7/site-packages/patsy/build.py\u001b[0m in \u001b[0;36m_examine_factor_types\u001b[0;34m(factors, factor_states, data_iter_maker, NA_action)\u001b[0m\n\u001b[1;32m    446\u001b[0m                     cat_sniffers[factor] = CategoricalSniffer(NA_action,\n\u001b[1;32m    447\u001b[0m                                                               factor.origin)\n\u001b[0;32m--> 448\u001b[0;31m                 \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcat_sniffers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msniff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m                     \u001b[0mexamine_needed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pip/git2net/pip_ds/lib/python3.7/site-packages/patsy/categorical.py\u001b[0m in \u001b[0;36msniff\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_categorical_shape_fix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pip/git2net/pip_ds/lib/python3.7/site-packages/patsy/categorical.py\u001b[0m in \u001b[0;36m_categorical_shape_fix\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;31m# wrong shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ndim\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mPatsyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"categorical data cannot be >1-dimensional\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m     \u001b[0;31m# coerce scalars into 1d, which is consistent with what we do for numeric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;31m# factors. (See statsmodels/statsmodels#1881)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPatsyError\u001b[0m: categorical data cannot be >1-dimensional"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as sm\n",
    "\n",
    "model = sm.ols(formula='productivity_per_second ~ pdf[X]', data = pdf)\n",
    "fit = model.fit()\n",
    "print(fit.summary())"
   ]
  }
 ]
}